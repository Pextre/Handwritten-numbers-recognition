{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peixo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 23s 378us/step - loss: 0.1175 - acc: 0.9648 - val_loss: 0.0410 - val_acc: 0.9876\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.0394 - acc: 0.9879 - val_loss: 0.0367 - val_acc: 0.9888\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0273 - acc: 0.9913 - val_loss: 0.0360 - val_acc: 0.9878\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0211 - acc: 0.9926 - val_loss: 0.0267 - val_acc: 0.9914\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 21s 357us/step - loss: 0.0148 - acc: 0.9955 - val_loss: 0.0316 - val_acc: 0.9911\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0377 - val_acc: 0.9909\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 21s 357us/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0363 - val_acc: 0.9907\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0315 - val_acc: 0.9919\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 21s 357us/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0455 - val_acc: 0.9904\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0479 - val_acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23b58876a20>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,  Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "gpu_option= tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_option))\n",
    "tf.device('/gpu:1')\n",
    "keras.backend.set_session(sess) #activates my gpu\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train , y_train),(x_test , y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "#one_hot encode the labels \n",
    "y_train =  keras.utils.to_categorical(y_train )\n",
    "y_test =  keras.utils.to_categorical(y_test )\n",
    "\n",
    "EPOCH=10\n",
    "BATC_SIZE=32\n",
    "\n",
    "NAME = f\"64-128-CNN{time.time()}\"\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "x_train = np.array(x_train).reshape(-1, 28, 28, 1)\n",
    "x_test = np.array(x_test).reshape(-1, 28, 28, 1)\n",
    "\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128,(4,4),input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(128,(4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train ,y_train ,batch_size =BATC_SIZE, epochs=EPOCH , validation_data=(x_test ,y_test),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('128x128-CNN-Numbers.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
